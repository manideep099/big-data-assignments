{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manideep099/big-data-assignments/blob/main/ICP6_Pothuraju_Manideep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Simple Neural Network with Keras Sequential API***"
      ],
      "metadata": {
        "id": "f8QdGW-45_Tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy as np\n",
        "\n",
        "# Generate some random data\n",
        "x_train = np.random.random((1000, 20))  # 1000 samples, 20 features each\n",
        "y_train = np.random.randint(2, size=(1000, 1))  # Binary labels (0 or 1)\n",
        "\n",
        "x_test = np.random.random((200, 20))  # 200 test samples\n",
        "y_test = np.random.randint(2, size=(200, 1))  # Binary labels for testing\n",
        "\n",
        "# Build a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add a hidden layer with 64 neurons and ReLU activation\n",
        "model.add(Dense(64, activation='relu', input_shape=(20,)))\n",
        "\n",
        "# Add another hidden layer with 32 neurons and ReLU activation\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Add an output layer with 1 neuron and sigmoid activation for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJpPAbBG6LWQ",
        "outputId": "db286ef2-7f82-4f42-ea92-165da49d3e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5066 - loss: 0.6951\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5088 - loss: 0.6919\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5747 - loss: 0.6863\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5611 - loss: 0.6868\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5560 - loss: 0.6840\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5073 - loss: 0.6963  \n",
            "Test accuracy: 0.49000000953674316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Sequential API to create and train a neural network for classifying the MNIST dataset.***"
      ],
      "metadata": {
        "id": "ske7X0_r33aI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data: normalize images and one-hot encode labels\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Build a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Flatten the input (28x28 images) into a vector of size 784\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "# Add a hidden layer with 128 neurons and ReLU activation\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Add the output layer with 10 neurons (one for each class) and softmax activation\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygO844pd3anG",
        "outputId": "a62cb8de-c912-48db-ace7-aa88bcd9512b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8689 - loss: 0.4777 - val_accuracy: 0.9557 - val_loss: 0.1540\n",
            "Epoch 2/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9614 - loss: 0.1317 - val_accuracy: 0.9638 - val_loss: 0.1221\n",
            "Epoch 3/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9732 - loss: 0.0899 - val_accuracy: 0.9689 - val_loss: 0.1025\n",
            "Epoch 4/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9818 - loss: 0.0627 - val_accuracy: 0.9683 - val_loss: 0.1044\n",
            "Epoch 5/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9859 - loss: 0.0484 - val_accuracy: 0.9755 - val_loss: 0.0878\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9718 - loss: 0.0882\n",
            "Test accuracy: 0.9764000177383423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Use the Sequential API to build a simple feedforward neural network.\n",
        "# 2. Include 5 hidden layers with ReLU activation and an output layer with Softmax activation.\n"
      ],
      "metadata": {
        "id": "yerv7zLL_ft0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. Load and Preprocess the Data ---\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the image data:\n",
        "# Normalize the pixel values from the range [0, 255] to [0.0, 1.0].\n",
        "# This helps the network learn more effectively.\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Preprocess the labels:\n",
        "# Convert the labels (integers 0-9) into a one-hot encoded format.\n",
        "# For example, the label '5' becomes a vector [0, 0, 0, 0, 0, 1, 0, 0, 0, 0].\n",
        "# This is necessary for categorical cross-entropy loss.\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "# --- 2. Build the Neural Network Model ---\n",
        "\n",
        "# Initialize a Sequential model. This is the simplest way to build a model in Keras,\n",
        "# allowing you to stack layers one after another.\n",
        "model = Sequential()\n",
        "\n",
        "# Add a Flatten layer to the model.\n",
        "# This layer takes the 28x28 pixel input images and \"flattens\" them into a\n",
        "# one-dimensional vector of 784 pixels (28 * 28 = 784).\n",
        "# This is required to feed the data into the fully connected (Dense) layers.\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "# Add the five hidden layers with ReLU activation.\n",
        "# 'Dense' means it's a fully connected layer.\n",
        "# 'ReLU' (Rectified Linear Unit) is a common activation function that helps introduce non-linearity.\n",
        "model.add(Dense(256, activation='relu')) # 1st Hidden Layer\n",
        "model.add(Dense(128, activation='relu')) # 2nd Hidden Layer\n",
        "model.add(Dense(64, activation='relu'))  # 3rd Hidden Layer\n",
        "model.add(Dense(64, activation='relu'))  # 4th Hidden Layer\n",
        "model.add(Dense(32, activation='relu'))  # 5th Hidden Layer\n",
        "\n",
        "# Add the output layer.\n",
        "# It has 10 neurons, one for each class (digits 0 through 9).\n",
        "# 'softmax' activation is used to output a probability distribution across the 10 classes.\n",
        "# The class with the highest probability is the model's prediction.\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "# --- 3. Compile the Model ---\n",
        "\n",
        "# Compile the model to configure the learning process.\n",
        "model.compile(optimizer='adam',                  # Adam is an efficient and popular optimization algorithm.\n",
        "              loss='categorical_crossentropy',   # This loss function is used for multi-class classification with one-hot encoded labels.\n",
        "              metrics=['accuracy'])              # We want to monitor the accuracy during training and evaluation.\n",
        "\n",
        "# Display a summary of the model's architecture\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# --- 4. Train the Model ---\n",
        "\n",
        "print(\"\\n--- Starting Model Training ---\")\n",
        "# Train the model using the training data.\n",
        "# epochs: The number of times the model will cycle through the entire training dataset.\n",
        "# batch_size: The number of samples processed before the model is updated.\n",
        "# validation_split: A fraction of the training data to be used as validation data.\n",
        "# The model will not be trained on this data, but its performance on it will be evaluated at the end of each epoch.\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=64,\n",
        "                    validation_split=0.2)\n",
        "\n",
        "\n",
        "# --- 5. Evaluate the Model ---\n",
        "\n",
        "print(\"\\n--- Evaluating Model on Test Data ---\")\n",
        "# Evaluate the final model's performance on the unseen test data.\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'\\nTest Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "\n",
        "# --- 6. Make a Prediction (Optional) ---\n",
        "\n",
        "# You can use the trained model to make predictions on new data.\n",
        "# Let's take a single image from the test set.\n",
        "sample_image = x_test[0]\n",
        "# The model expects a batch of images, so we add a dimension.\n",
        "sample_image = np.expand_dims(sample_image, axis=0)\n",
        "\n",
        "# Get the model's prediction.\n",
        "prediction = model.predict(sample_image)\n",
        "\n",
        "# The prediction is an array of probabilities. Find the class with the highest probability.\n",
        "predicted_class = np.argmax(prediction)\n",
        "actual_class = np.argmax(y_test[0]) # Get the actual label for comparison\n",
        "\n",
        "print(f\"\\n--- Prediction Example ---\")\n",
        "print(f\"Predicted Digit: {predicted_class}\")\n",
        "print(f\"Actual Digit: {actual_class}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "id": "of0kzeh0_a-t",
        "outputId": "52700a2d-5cc3-4a33-93b5-75f9120bb587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_29\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_29\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten_9 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_191 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m200,960\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_192 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_193 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_194 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_195 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_196 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_191 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_192 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_193 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_194 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_195 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_196 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m248,682\u001b[0m (971.41 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">248,682</span> (971.41 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m248,682\u001b[0m (971.41 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">248,682</span> (971.41 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Model Training ---\n",
            "Epoch 1/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.8056 - loss: 0.6183 - val_accuracy: 0.9528 - val_loss: 0.1501\n",
            "Epoch 2/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9632 - loss: 0.1195 - val_accuracy: 0.9656 - val_loss: 0.1128\n",
            "Epoch 3/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9747 - loss: 0.0818 - val_accuracy: 0.9735 - val_loss: 0.0907\n",
            "Epoch 4/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9835 - loss: 0.0538 - val_accuracy: 0.9680 - val_loss: 0.1111\n",
            "Epoch 5/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9845 - loss: 0.0499 - val_accuracy: 0.9754 - val_loss: 0.0900\n",
            "Epoch 6/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9878 - loss: 0.0386 - val_accuracy: 0.9738 - val_loss: 0.0992\n",
            "Epoch 7/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9898 - loss: 0.0313 - val_accuracy: 0.9691 - val_loss: 0.1162\n",
            "Epoch 8/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9903 - loss: 0.0292 - val_accuracy: 0.9734 - val_loss: 0.1078\n",
            "Epoch 9/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9911 - loss: 0.0288 - val_accuracy: 0.9712 - val_loss: 0.1104\n",
            "Epoch 10/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9928 - loss: 0.0232 - val_accuracy: 0.9768 - val_loss: 0.1032\n",
            "\n",
            "--- Evaluating Model on Test Data ---\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9755 - loss: 0.1085\n",
            "\n",
            "Test Loss: 0.0884\n",
            "Test Accuracy: 0.9793\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
            "\n",
            "--- Prediction Example ---\n",
            "Predicted Digit: 7\n",
            "Actual Digit: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Try adding more layers or using a different number of neurons.\n",
        "# 4. Experiment with different activation functions (e.g., tanh, sigmoid).\n",
        "# 5. Compare results with different optimizers like sgd, rmsprop, etc.\n",
        "# 6. Your model should achieve a test accuracy above 99%, given the simplicity of the dataset."
      ],
      "metadata": {
        "id": "Bz9s1X2uAS2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. Load and Preprocess the Data ---\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# --- Reshape data for ImageDataGenerator and model ---\n",
        "# The data generator requires a 4D tensor (batch, height, width, channels).\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "# Normalize the pixel values from the range [0, 255] to [0.0, 1.0].\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode the labels.\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "# --- 2. Build the Dense Feedforward Neural Network ---\n",
        "\n",
        "# Initialize a Sequential model.\n",
        "model = Sequential()\n",
        "\n",
        "# Flatten the input (28x28x1 images) into a vector of size 784\n",
        "model.add(Flatten(input_shape=(28, 28, 1)))\n",
        "\n",
        "# A deep and wide architecture with Dropout for regularization.\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Output Layer: 10 neurons for 10 classes with softmax activation.\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "# --- 3. Compile the Model ---\n",
        "\n",
        "# We'll use the 'adam' optimizer.\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display a summary of the model's architecture\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# --- 4. Set up Data Augmentation and Callbacks ---\n",
        "\n",
        "# --- Data Augmentation ---\n",
        "# Create an ImageDataGenerator to apply real-time data augmentation.\n",
        "# This helps prevent overfitting and improves model generalization.\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,      # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    zoom_range=0.1,         # Randomly zoom image\n",
        "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.1, # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=False,  # don't flip images horizontally\n",
        "    vertical_flip=False)    # don't flip images vertically\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# --- Learning Rate Annealer ---\n",
        "# This callback reduces the learning rate when a metric has stopped improving.\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                            patience=3,\n",
        "                                            verbose=1,\n",
        "                                            factor=0.5,\n",
        "                                            min_lr=0.00001)\n",
        "\n",
        "# --- 5. Train the Model ---\n",
        "\n",
        "print(\"\\n--- Starting Model Training with Data Augmentation ---\")\n",
        "# Train the model using the generator.\n",
        "# Increased epochs to give the model time to learn from augmented data.\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=64),\n",
        "                    epochs=40,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    verbose=1,\n",
        "                    callbacks=[learning_rate_reduction])\n",
        "\n",
        "\n",
        "# --- 6. Evaluate the Model ---\n",
        "\n",
        "print(\"\\n--- Evaluating Model on Test Data ---\")\n",
        "# Evaluate the final model's performance on the unseen test data.\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f'\\nTest Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "\n",
        "# --- 7. Make a Prediction (Optional) ---\n",
        "\n",
        "# You can use the trained model to make predictions on new data.\n",
        "sample_image = x_test[0]\n",
        "sample_image_batch = np.expand_dims(sample_image, axis=0)\n",
        "\n",
        "prediction = model.predict(sample_image_batch)\n",
        "predicted_class = np.argmax(prediction)\n",
        "actual_class = np.argmax(y_test[0])\n",
        "\n",
        "print(f\"\\n--- Prediction Example ---\")\n",
        "print(f\"Predicted Digit: {predicted_class}\")\n",
        "print(f\"Actual Digit: {actual_class}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iWMFiMh1AX8O",
        "outputId": "d4dfb394-3f7c-44ac-e1a9-cf71667c8e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_32\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_32\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten_12 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_205 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m401,920\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_206 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_207 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_208 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_205 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_206 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_207 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_208 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m567,434\u001b[0m (2.16 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">567,434</span> (2.16 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m567,434\u001b[0m (2.16 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">567,434</span> (2.16 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Model Training with Data Augmentation ---\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.6998 - loss: 0.8931 - val_accuracy: 0.9552 - val_loss: 0.1378 - learning_rate: 0.0010\n",
            "Epoch 2/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9135 - loss: 0.2759 - val_accuracy: 0.9704 - val_loss: 0.0895 - learning_rate: 0.0010\n",
            "Epoch 3/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9309 - loss: 0.2294 - val_accuracy: 0.9739 - val_loss: 0.0848 - learning_rate: 0.0010\n",
            "Epoch 4/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 34ms/step - accuracy: 0.9420 - loss: 0.1935 - val_accuracy: 0.9729 - val_loss: 0.0827 - learning_rate: 0.0010\n",
            "Epoch 5/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9452 - loss: 0.1817 - val_accuracy: 0.9792 - val_loss: 0.0668 - learning_rate: 0.0010\n",
            "Epoch 6/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9495 - loss: 0.1734 - val_accuracy: 0.9802 - val_loss: 0.0665 - learning_rate: 0.0010\n",
            "Epoch 7/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9503 - loss: 0.1660 - val_accuracy: 0.9828 - val_loss: 0.0544 - learning_rate: 0.0010\n",
            "Epoch 8/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9556 - loss: 0.1518 - val_accuracy: 0.9817 - val_loss: 0.0578 - learning_rate: 0.0010\n",
            "Epoch 9/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.9560 - loss: 0.1472 - val_accuracy: 0.9840 - val_loss: 0.0551 - learning_rate: 0.0010\n",
            "Epoch 10/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9578 - loss: 0.1443 - val_accuracy: 0.9848 - val_loss: 0.0466 - learning_rate: 0.0010\n",
            "Epoch 11/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9578 - loss: 0.1396 - val_accuracy: 0.9833 - val_loss: 0.0544 - learning_rate: 0.0010\n",
            "Epoch 12/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9595 - loss: 0.1352 - val_accuracy: 0.9837 - val_loss: 0.0515 - learning_rate: 0.0010\n",
            "Epoch 13/40\n",
            "\u001b[1m936/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9595 - loss: 0.1355\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9596 - loss: 0.1355 - val_accuracy: 0.9843 - val_loss: 0.0497 - learning_rate: 0.0010\n",
            "Epoch 14/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 34ms/step - accuracy: 0.9644 - loss: 0.1202 - val_accuracy: 0.9884 - val_loss: 0.0394 - learning_rate: 5.0000e-04\n",
            "Epoch 15/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 33ms/step - accuracy: 0.9697 - loss: 0.1014 - val_accuracy: 0.9883 - val_loss: 0.0368 - learning_rate: 5.0000e-04\n",
            "Epoch 16/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9701 - loss: 0.0996 - val_accuracy: 0.9880 - val_loss: 0.0378 - learning_rate: 5.0000e-04\n",
            "Epoch 17/40\n",
            "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9714 - loss: 0.0923\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9714 - loss: 0.0923 - val_accuracy: 0.9881 - val_loss: 0.0366 - learning_rate: 5.0000e-04\n",
            "Epoch 18/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9731 - loss: 0.0911 - val_accuracy: 0.9892 - val_loss: 0.0336 - learning_rate: 2.5000e-04\n",
            "Epoch 19/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9735 - loss: 0.0900 - val_accuracy: 0.9897 - val_loss: 0.0327 - learning_rate: 2.5000e-04\n",
            "Epoch 20/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9749 - loss: 0.0830 - val_accuracy: 0.9894 - val_loss: 0.0323 - learning_rate: 2.5000e-04\n",
            "Epoch 21/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9769 - loss: 0.0778 - val_accuracy: 0.9901 - val_loss: 0.0318 - learning_rate: 2.5000e-04\n",
            "Epoch 22/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9743 - loss: 0.0831 - val_accuracy: 0.9901 - val_loss: 0.0319 - learning_rate: 2.5000e-04\n",
            "Epoch 23/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.9753 - loss: 0.0796 - val_accuracy: 0.9898 - val_loss: 0.0319 - learning_rate: 2.5000e-04\n",
            "Epoch 24/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9773 - loss: 0.0762 - val_accuracy: 0.9905 - val_loss: 0.0322 - learning_rate: 2.5000e-04\n",
            "Epoch 25/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9769 - loss: 0.0752 - val_accuracy: 0.9912 - val_loss: 0.0279 - learning_rate: 2.5000e-04\n",
            "Epoch 26/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9773 - loss: 0.0712 - val_accuracy: 0.9896 - val_loss: 0.0313 - learning_rate: 2.5000e-04\n",
            "Epoch 27/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9774 - loss: 0.0774 - val_accuracy: 0.9894 - val_loss: 0.0303 - learning_rate: 2.5000e-04\n",
            "Epoch 28/40\n",
            "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9763 - loss: 0.0779\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9763 - loss: 0.0779 - val_accuracy: 0.9901 - val_loss: 0.0282 - learning_rate: 2.5000e-04\n",
            "Epoch 29/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 34ms/step - accuracy: 0.9768 - loss: 0.0741 - val_accuracy: 0.9904 - val_loss: 0.0284 - learning_rate: 1.2500e-04\n",
            "Epoch 30/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9789 - loss: 0.0658 - val_accuracy: 0.9898 - val_loss: 0.0300 - learning_rate: 1.2500e-04\n",
            "Epoch 31/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 34ms/step - accuracy: 0.9808 - loss: 0.0652 - val_accuracy: 0.9915 - val_loss: 0.0268 - learning_rate: 1.2500e-04\n",
            "Epoch 32/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9776 - loss: 0.0744 - val_accuracy: 0.9905 - val_loss: 0.0275 - learning_rate: 1.2500e-04\n",
            "Epoch 33/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9803 - loss: 0.0668 - val_accuracy: 0.9908 - val_loss: 0.0261 - learning_rate: 1.2500e-04\n",
            "Epoch 34/40\n",
            "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9801 - loss: 0.0632\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9801 - loss: 0.0632 - val_accuracy: 0.9912 - val_loss: 0.0274 - learning_rate: 1.2500e-04\n",
            "Epoch 35/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 34ms/step - accuracy: 0.9799 - loss: 0.0662 - val_accuracy: 0.9913 - val_loss: 0.0273 - learning_rate: 6.2500e-05\n",
            "Epoch 36/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9797 - loss: 0.0650 - val_accuracy: 0.9907 - val_loss: 0.0272 - learning_rate: 6.2500e-05\n",
            "Epoch 37/40\n",
            "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9800 - loss: 0.0636\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 33ms/step - accuracy: 0.9800 - loss: 0.0636 - val_accuracy: 0.9915 - val_loss: 0.0265 - learning_rate: 6.2500e-05\n",
            "Epoch 38/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9807 - loss: 0.0610 - val_accuracy: 0.9915 - val_loss: 0.0260 - learning_rate: 3.1250e-05\n",
            "Epoch 39/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9808 - loss: 0.0637 - val_accuracy: 0.9914 - val_loss: 0.0257 - learning_rate: 3.1250e-05\n",
            "Epoch 40/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9798 - loss: 0.0634\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 34ms/step - accuracy: 0.9798 - loss: 0.0634 - val_accuracy: 0.9912 - val_loss: 0.0263 - learning_rate: 3.1250e-05\n",
            "\n",
            "--- Evaluating Model on Test Data ---\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.9912 - loss: 0.0263\n",
            "\n",
            "Test Loss: 0.0263\n",
            "Test Accuracy: 0.9912\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
            "\n",
            "--- Prediction Example ---\n",
            "Predicted Digit: 7\n",
            "Actual Digit: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# --- 1. Load and Preprocess the Data ---\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# --- Reshape data for ImageDataGenerator and model ---\n",
        "# The data generator requires a 4D tensor (batch, height, width, channels).\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "# Normalize the pixel values from the range [0, 255] to [0.0, 1.0].\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode the labels.\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "# --- 2. Function to Build the Model ---\n",
        "# This function creates the exact Dense network architecture that achieved >99% accuracy.\n",
        "def build_model():\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(28, 28, 1)))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "\n",
        "# --- 3. Set up Data Augmentation ---\n",
        "# This is defined once and used for training each model.\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1)\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "\n",
        "# --- 4. Loop Through Optimizers to Compare Results ---\n",
        "\n",
        "optimizers_to_test = ['adam', 'rmsprop', 'sgd']\n",
        "results = []\n",
        "epochs_for_comparison = 40 # Using 40 epochs as in the successful run\n",
        "\n",
        "for optimizer_name in optimizers_to_test:\n",
        "    print(f\"\\n--- Training with Optimizer: {optimizer_name.upper()} ---\")\n",
        "\n",
        "    # Build a fresh model\n",
        "    model = build_model()\n",
        "\n",
        "    # Compile the model with the current optimizer\n",
        "    model.compile(optimizer=optimizer_name,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Set up a new learning rate reducer for each model\n",
        "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                                patience=3,\n",
        "                                                verbose=1,\n",
        "                                                factor=0.5,\n",
        "                                                min_lr=0.00001)\n",
        "\n",
        "    # Train the model using the successful configuration\n",
        "    history = model.fit(datagen.flow(x_train, y_train, batch_size=64),\n",
        "                        epochs=epochs_for_comparison,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        verbose=1,\n",
        "                        callbacks=[learning_rate_reduction])\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(f\"\\n--- Evaluating Optimizer: {optimizer_name.upper()} ---\")\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "\n",
        "    # Store results\n",
        "    results.append({\n",
        "        'optimizer': optimizer_name,\n",
        "        'test_loss': test_loss,\n",
        "        'test_accuracy': test_acc\n",
        "    })\n",
        "\n",
        "\n",
        "# --- 5. Display Comparison Summary ---\n",
        "\n",
        "print(\"\\n\\n--- Optimizer Comparison Summary ---\")\n",
        "# Using pandas for a nicely formatted table\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDAFCD3oKKN5",
        "outputId": "d3df321a-dd59-4cbf-94e6-9bcf4d8197dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training with Optimizer: ADAM ---\n",
            "Epoch 1/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 33ms/step - accuracy: 0.6950 - loss: 0.9136 - val_accuracy: 0.9531 - val_loss: 0.1499 - learning_rate: 0.0010\n",
            "Epoch 2/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9113 - loss: 0.2876 - val_accuracy: 0.9718 - val_loss: 0.0899 - learning_rate: 0.0010\n",
            "Epoch 3/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9316 - loss: 0.2262 - val_accuracy: 0.9752 - val_loss: 0.0779 - learning_rate: 0.0010\n",
            "Epoch 4/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 34ms/step - accuracy: 0.9394 - loss: 0.1976 - val_accuracy: 0.9759 - val_loss: 0.0787 - learning_rate: 0.0010\n",
            "Epoch 5/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9457 - loss: 0.1826 - val_accuracy: 0.9797 - val_loss: 0.0648 - learning_rate: 0.0010\n",
            "Epoch 6/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 34ms/step - accuracy: 0.9497 - loss: 0.1683 - val_accuracy: 0.9791 - val_loss: 0.0703 - learning_rate: 0.0010\n",
            "Epoch 7/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9503 - loss: 0.1631 - val_accuracy: 0.9807 - val_loss: 0.0609 - learning_rate: 0.0010\n",
            "Epoch 8/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9536 - loss: 0.1542 - val_accuracy: 0.9799 - val_loss: 0.0604 - learning_rate: 0.0010\n",
            "Epoch 9/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9559 - loss: 0.1473 - val_accuracy: 0.9832 - val_loss: 0.0515 - learning_rate: 0.0010\n",
            "Epoch 10/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9571 - loss: 0.1387 - val_accuracy: 0.9811 - val_loss: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 11/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9603 - loss: 0.1363 - val_accuracy: 0.9821 - val_loss: 0.0574 - learning_rate: 0.0010\n",
            "Epoch 12/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9604 - loss: 0.1315 - val_accuracy: 0.9838 - val_loss: 0.0512 - learning_rate: 0.0010\n",
            "Epoch 13/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - accuracy: 0.9631 - loss: 0.1256 - val_accuracy: 0.9844 - val_loss: 0.0492 - learning_rate: 0.0010\n",
            "Epoch 14/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9625 - loss: 0.1278 - val_accuracy: 0.9835 - val_loss: 0.0495 - learning_rate: 0.0010\n",
            "Epoch 15/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 34ms/step - accuracy: 0.9613 - loss: 0.1272 - val_accuracy: 0.9854 - val_loss: 0.0445 - learning_rate: 0.0010\n",
            "Epoch 16/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 33ms/step - accuracy: 0.9641 - loss: 0.1215 - val_accuracy: 0.9856 - val_loss: 0.0450 - learning_rate: 0.0010\n",
            "Epoch 17/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 31ms/step - accuracy: 0.9633 - loss: 0.1225 - val_accuracy: 0.9854 - val_loss: 0.0472 - learning_rate: 0.0010\n",
            "Epoch 18/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9644 - loss: 0.1182 - val_accuracy: 0.9864 - val_loss: 0.0407 - learning_rate: 0.0010\n",
            "Epoch 19/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9654 - loss: 0.1158 - val_accuracy: 0.9849 - val_loss: 0.0422 - learning_rate: 0.0010\n",
            "Epoch 20/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 31ms/step - accuracy: 0.9661 - loss: 0.1121 - val_accuracy: 0.9863 - val_loss: 0.0405 - learning_rate: 0.0010\n",
            "Epoch 21/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9668 - loss: 0.1152 - val_accuracy: 0.9869 - val_loss: 0.0411 - learning_rate: 0.0010\n",
            "Epoch 22/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9660 - loss: 0.1150 - val_accuracy: 0.9832 - val_loss: 0.0495 - learning_rate: 0.0010\n",
            "Epoch 23/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9666 - loss: 0.1095 - val_accuracy: 0.9876 - val_loss: 0.0405 - learning_rate: 0.0010\n",
            "Epoch 24/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - accuracy: 0.9674 - loss: 0.1115 - val_accuracy: 0.9878 - val_loss: 0.0389 - learning_rate: 0.0010\n",
            "Epoch 25/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9691 - loss: 0.1017 - val_accuracy: 0.9876 - val_loss: 0.0388 - learning_rate: 0.0010\n",
            "Epoch 26/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9667 - loss: 0.1081 - val_accuracy: 0.9873 - val_loss: 0.0394 - learning_rate: 0.0010\n",
            "Epoch 27/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9684 - loss: 0.1046\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 34ms/step - accuracy: 0.9684 - loss: 0.1046 - val_accuracy: 0.9875 - val_loss: 0.0417 - learning_rate: 0.0010\n",
            "Epoch 28/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9714 - loss: 0.0959 - val_accuracy: 0.9890 - val_loss: 0.0334 - learning_rate: 5.0000e-04\n",
            "Epoch 29/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9749 - loss: 0.0867 - val_accuracy: 0.9900 - val_loss: 0.0301 - learning_rate: 5.0000e-04\n",
            "Epoch 30/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9744 - loss: 0.0857 - val_accuracy: 0.9898 - val_loss: 0.0334 - learning_rate: 5.0000e-04\n",
            "Epoch 31/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9743 - loss: 0.0856 - val_accuracy: 0.9902 - val_loss: 0.0303 - learning_rate: 5.0000e-04\n",
            "Epoch 32/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9749 - loss: 0.0816 - val_accuracy: 0.9892 - val_loss: 0.0318 - learning_rate: 5.0000e-04\n",
            "Epoch 33/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9743 - loss: 0.0859 - val_accuracy: 0.9903 - val_loss: 0.0282 - learning_rate: 5.0000e-04\n",
            "Epoch 34/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9775 - loss: 0.0748 - val_accuracy: 0.9894 - val_loss: 0.0327 - learning_rate: 5.0000e-04\n",
            "Epoch 35/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - accuracy: 0.9779 - loss: 0.0739 - val_accuracy: 0.9905 - val_loss: 0.0302 - learning_rate: 5.0000e-04\n",
            "Epoch 36/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9760 - loss: 0.0806 - val_accuracy: 0.9900 - val_loss: 0.0329 - learning_rate: 5.0000e-04\n",
            "Epoch 37/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.9758 - loss: 0.0773 - val_accuracy: 0.9912 - val_loss: 0.0287 - learning_rate: 5.0000e-04\n",
            "Epoch 38/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9775 - loss: 0.0755 - val_accuracy: 0.9911 - val_loss: 0.0271 - learning_rate: 5.0000e-04\n",
            "Epoch 39/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9746 - loss: 0.0814 - val_accuracy: 0.9907 - val_loss: 0.0295 - learning_rate: 5.0000e-04\n",
            "Epoch 40/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9786 - loss: 0.0724\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9786 - loss: 0.0724 - val_accuracy: 0.9908 - val_loss: 0.0289 - learning_rate: 5.0000e-04\n",
            "\n",
            "--- Evaluating Optimizer: ADAM ---\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.9908 - loss: 0.0289\n",
            "\n",
            "--- Training with Optimizer: RMSPROP ---\n",
            "Epoch 1/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 34ms/step - accuracy: 0.7051 - loss: 0.8930 - val_accuracy: 0.9615 - val_loss: 0.1289 - learning_rate: 0.0010\n",
            "Epoch 2/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9122 - loss: 0.2927 - val_accuracy: 0.9706 - val_loss: 0.0867 - learning_rate: 0.0010\n",
            "Epoch 3/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9305 - loss: 0.2401 - val_accuracy: 0.9758 - val_loss: 0.0843 - learning_rate: 0.0010\n",
            "Epoch 4/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9411 - loss: 0.2124 - val_accuracy: 0.9778 - val_loss: 0.0740 - learning_rate: 0.0010\n",
            "Epoch 5/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9432 - loss: 0.2045 - val_accuracy: 0.9732 - val_loss: 0.0813 - learning_rate: 0.0010\n",
            "Epoch 6/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9472 - loss: 0.1932 - val_accuracy: 0.9808 - val_loss: 0.0654 - learning_rate: 0.0010\n",
            "Epoch 7/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9469 - loss: 0.2007 - val_accuracy: 0.9836 - val_loss: 0.0575 - learning_rate: 0.0010\n",
            "Epoch 8/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9491 - loss: 0.1929 - val_accuracy: 0.9810 - val_loss: 0.0649 - learning_rate: 0.0010\n",
            "Epoch 9/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9512 - loss: 0.1890 - val_accuracy: 0.9791 - val_loss: 0.0656 - learning_rate: 0.0010\n",
            "Epoch 10/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9536 - loss: 0.1830\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 34ms/step - accuracy: 0.9536 - loss: 0.1830 - val_accuracy: 0.9811 - val_loss: 0.0672 - learning_rate: 0.0010\n",
            "Epoch 11/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9581 - loss: 0.1713 - val_accuracy: 0.9861 - val_loss: 0.0472 - learning_rate: 5.0000e-04\n",
            "Epoch 12/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9604 - loss: 0.1640 - val_accuracy: 0.9855 - val_loss: 0.0526 - learning_rate: 5.0000e-04\n",
            "Epoch 13/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9603 - loss: 0.1575 - val_accuracy: 0.9848 - val_loss: 0.0514 - learning_rate: 5.0000e-04\n",
            "Epoch 14/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9628 - loss: 0.1483\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 31ms/step - accuracy: 0.9628 - loss: 0.1483 - val_accuracy: 0.9854 - val_loss: 0.0497 - learning_rate: 5.0000e-04\n",
            "Epoch 15/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9655 - loss: 0.1453 - val_accuracy: 0.9876 - val_loss: 0.0421 - learning_rate: 2.5000e-04\n",
            "Epoch 16/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.9673 - loss: 0.1390 - val_accuracy: 0.9874 - val_loss: 0.0453 - learning_rate: 2.5000e-04\n",
            "Epoch 17/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9658 - loss: 0.1413 - val_accuracy: 0.9868 - val_loss: 0.0435 - learning_rate: 2.5000e-04\n",
            "Epoch 18/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9665 - loss: 0.1450 - val_accuracy: 0.9886 - val_loss: 0.0446 - learning_rate: 2.5000e-04\n",
            "Epoch 19/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9677 - loss: 0.1348 - val_accuracy: 0.9875 - val_loss: 0.0452 - learning_rate: 2.5000e-04\n",
            "Epoch 20/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9688 - loss: 0.1309 - val_accuracy: 0.9885 - val_loss: 0.0414 - learning_rate: 2.5000e-04\n",
            "Epoch 21/40\n",
            "\u001b[1m936/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9681 - loss: 0.1317\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9681 - loss: 0.1317 - val_accuracy: 0.9887 - val_loss: 0.0408 - learning_rate: 2.5000e-04\n",
            "Epoch 22/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 31ms/step - accuracy: 0.9680 - loss: 0.1313 - val_accuracy: 0.9885 - val_loss: 0.0419 - learning_rate: 1.2500e-04\n",
            "Epoch 23/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9692 - loss: 0.1346 - val_accuracy: 0.9886 - val_loss: 0.0419 - learning_rate: 1.2500e-04\n",
            "Epoch 24/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - accuracy: 0.9695 - loss: 0.1212 - val_accuracy: 0.9898 - val_loss: 0.0386 - learning_rate: 1.2500e-04\n",
            "Epoch 25/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 31ms/step - accuracy: 0.9715 - loss: 0.1257 - val_accuracy: 0.9893 - val_loss: 0.0404 - learning_rate: 1.2500e-04\n",
            "Epoch 26/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9704 - loss: 0.1314 - val_accuracy: 0.9885 - val_loss: 0.0390 - learning_rate: 1.2500e-04\n",
            "Epoch 27/40\n",
            "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9716 - loss: 0.1257\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 33ms/step - accuracy: 0.9716 - loss: 0.1257 - val_accuracy: 0.9893 - val_loss: 0.0360 - learning_rate: 1.2500e-04\n",
            "Epoch 28/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - accuracy: 0.9699 - loss: 0.1247 - val_accuracy: 0.9889 - val_loss: 0.0373 - learning_rate: 6.2500e-05\n",
            "Epoch 29/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9719 - loss: 0.1196 - val_accuracy: 0.9895 - val_loss: 0.0369 - learning_rate: 6.2500e-05\n",
            "Epoch 30/40\n",
            "\u001b[1m936/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9704 - loss: 0.1209\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9705 - loss: 0.1209 - val_accuracy: 0.9896 - val_loss: 0.0371 - learning_rate: 6.2500e-05\n",
            "Epoch 31/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 35ms/step - accuracy: 0.9730 - loss: 0.1165 - val_accuracy: 0.9894 - val_loss: 0.0373 - learning_rate: 3.1250e-05\n",
            "Epoch 32/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9716 - loss: 0.1229 - val_accuracy: 0.9893 - val_loss: 0.0363 - learning_rate: 3.1250e-05\n",
            "Epoch 33/40\n",
            "\u001b[1m936/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9706 - loss: 0.1213\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9706 - loss: 0.1213 - val_accuracy: 0.9895 - val_loss: 0.0361 - learning_rate: 3.1250e-05\n",
            "Epoch 34/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 33ms/step - accuracy: 0.9726 - loss: 0.1183 - val_accuracy: 0.9894 - val_loss: 0.0363 - learning_rate: 1.5625e-05\n",
            "Epoch 35/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9720 - loss: 0.1224 - val_accuracy: 0.9896 - val_loss: 0.0359 - learning_rate: 1.5625e-05\n",
            "Epoch 36/40\n",
            "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9724 - loss: 0.1136\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 31ms/step - accuracy: 0.9724 - loss: 0.1136 - val_accuracy: 0.9896 - val_loss: 0.0363 - learning_rate: 1.5625e-05\n",
            "Epoch 37/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 34ms/step - accuracy: 0.9735 - loss: 0.1182 - val_accuracy: 0.9891 - val_loss: 0.0361 - learning_rate: 1.0000e-05\n",
            "Epoch 38/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 31ms/step - accuracy: 0.9719 - loss: 0.1117 - val_accuracy: 0.9895 - val_loss: 0.0359 - learning_rate: 1.0000e-05\n",
            "Epoch 39/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9720 - loss: 0.1175 - val_accuracy: 0.9893 - val_loss: 0.0363 - learning_rate: 1.0000e-05\n",
            "Epoch 40/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 34ms/step - accuracy: 0.9738 - loss: 0.1117 - val_accuracy: 0.9892 - val_loss: 0.0358 - learning_rate: 1.0000e-05\n",
            "\n",
            "--- Evaluating Optimizer: RMSPROP ---\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.9892 - loss: 0.0358\n",
            "\n",
            "--- Training with Optimizer: SGD ---\n",
            "Epoch 1/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.2762 - loss: 2.0502 - val_accuracy: 0.8213 - val_loss: 0.7240 - learning_rate: 0.0100\n",
            "Epoch 2/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.6045 - loss: 1.2049 - val_accuracy: 0.8963 - val_loss: 0.4438 - learning_rate: 0.0100\n",
            "Epoch 3/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.7132 - loss: 0.8948 - val_accuracy: 0.9234 - val_loss: 0.3196 - learning_rate: 0.0100\n",
            "Epoch 4/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 30ms/step - accuracy: 0.7802 - loss: 0.7035 - val_accuracy: 0.9363 - val_loss: 0.2442 - learning_rate: 0.0100\n",
            "Epoch 5/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.8191 - loss: 0.5857 - val_accuracy: 0.9498 - val_loss: 0.1969 - learning_rate: 0.0100\n",
            "Epoch 6/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.8422 - loss: 0.5070 - val_accuracy: 0.9539 - val_loss: 0.1700 - learning_rate: 0.0100\n",
            "Epoch 7/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.8644 - loss: 0.4431 - val_accuracy: 0.9556 - val_loss: 0.1558 - learning_rate: 0.0100\n",
            "Epoch 8/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.8732 - loss: 0.4085 - val_accuracy: 0.9594 - val_loss: 0.1383 - learning_rate: 0.0100\n",
            "Epoch 9/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 32ms/step - accuracy: 0.8860 - loss: 0.3790 - val_accuracy: 0.9609 - val_loss: 0.1279 - learning_rate: 0.0100\n",
            "Epoch 10/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 30ms/step - accuracy: 0.8935 - loss: 0.3492 - val_accuracy: 0.9634 - val_loss: 0.1204 - learning_rate: 0.0100\n",
            "Epoch 11/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.9008 - loss: 0.3288 - val_accuracy: 0.9669 - val_loss: 0.1132 - learning_rate: 0.0100\n",
            "Epoch 12/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.9071 - loss: 0.3065 - val_accuracy: 0.9671 - val_loss: 0.1103 - learning_rate: 0.0100\n",
            "Epoch 13/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.9110 - loss: 0.2960 - val_accuracy: 0.9691 - val_loss: 0.1017 - learning_rate: 0.0100\n",
            "Epoch 14/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9145 - loss: 0.2797 - val_accuracy: 0.9690 - val_loss: 0.0995 - learning_rate: 0.0100\n",
            "Epoch 15/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 31ms/step - accuracy: 0.9161 - loss: 0.2789 - val_accuracy: 0.9703 - val_loss: 0.0944 - learning_rate: 0.0100\n",
            "Epoch 16/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.9205 - loss: 0.2625 - val_accuracy: 0.9708 - val_loss: 0.0927 - learning_rate: 0.0100\n",
            "Epoch 17/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.9239 - loss: 0.2525 - val_accuracy: 0.9718 - val_loss: 0.0878 - learning_rate: 0.0100\n",
            "Epoch 18/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.9264 - loss: 0.2457 - val_accuracy: 0.9735 - val_loss: 0.0847 - learning_rate: 0.0100\n",
            "Epoch 19/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.9306 - loss: 0.2315 - val_accuracy: 0.9731 - val_loss: 0.0824 - learning_rate: 0.0100\n",
            "Epoch 20/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.9320 - loss: 0.2221 - val_accuracy: 0.9743 - val_loss: 0.0810 - learning_rate: 0.0100\n",
            "Epoch 21/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.9306 - loss: 0.2262 - val_accuracy: 0.9727 - val_loss: 0.0789 - learning_rate: 0.0100\n",
            "Epoch 22/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 31ms/step - accuracy: 0.9347 - loss: 0.2180 - val_accuracy: 0.9759 - val_loss: 0.0748 - learning_rate: 0.0100\n",
            "Epoch 23/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.9368 - loss: 0.2087 - val_accuracy: 0.9757 - val_loss: 0.0743 - learning_rate: 0.0100\n",
            "Epoch 24/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.9371 - loss: 0.2102 - val_accuracy: 0.9759 - val_loss: 0.0735 - learning_rate: 0.0100\n",
            "Epoch 25/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.9399 - loss: 0.2006 - val_accuracy: 0.9772 - val_loss: 0.0713 - learning_rate: 0.0100\n",
            "Epoch 26/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.9399 - loss: 0.2017 - val_accuracy: 0.9769 - val_loss: 0.0680 - learning_rate: 0.0100\n",
            "Epoch 27/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.9434 - loss: 0.1902 - val_accuracy: 0.9766 - val_loss: 0.0691 - learning_rate: 0.0100\n",
            "Epoch 28/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 33ms/step - accuracy: 0.9438 - loss: 0.1834 - val_accuracy: 0.9778 - val_loss: 0.0680 - learning_rate: 0.0100\n",
            "Epoch 29/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.9443 - loss: 0.1847 - val_accuracy: 0.9785 - val_loss: 0.0651 - learning_rate: 0.0100\n",
            "Epoch 30/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.9435 - loss: 0.1881 - val_accuracy: 0.9786 - val_loss: 0.0641 - learning_rate: 0.0100\n",
            "Epoch 31/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.9462 - loss: 0.1795 - val_accuracy: 0.9786 - val_loss: 0.0631 - learning_rate: 0.0100\n",
            "Epoch 32/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.9464 - loss: 0.1789 - val_accuracy: 0.9794 - val_loss: 0.0633 - learning_rate: 0.0100\n",
            "Epoch 33/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9495 - loss: 0.1744 - val_accuracy: 0.9799 - val_loss: 0.0595 - learning_rate: 0.0100\n",
            "Epoch 34/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 31ms/step - accuracy: 0.9474 - loss: 0.1748 - val_accuracy: 0.9805 - val_loss: 0.0621 - learning_rate: 0.0100\n",
            "Epoch 35/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 31ms/step - accuracy: 0.9489 - loss: 0.1690 - val_accuracy: 0.9809 - val_loss: 0.0606 - learning_rate: 0.0100\n",
            "Epoch 36/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.9482 - loss: 0.1713 - val_accuracy: 0.9794 - val_loss: 0.0578 - learning_rate: 0.0100\n",
            "Epoch 37/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.9490 - loss: 0.1649 - val_accuracy: 0.9823 - val_loss: 0.0574 - learning_rate: 0.0100\n",
            "Epoch 38/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.9536 - loss: 0.1585 - val_accuracy: 0.9813 - val_loss: 0.0574 - learning_rate: 0.0100\n",
            "Epoch 39/40\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - accuracy: 0.9511 - loss: 0.1622 - val_accuracy: 0.9817 - val_loss: 0.0571 - learning_rate: 0.0100\n",
            "Epoch 40/40\n",
            "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9517 - loss: 0.1594\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.9517 - loss: 0.1594 - val_accuracy: 0.9823 - val_loss: 0.0540 - learning_rate: 0.0100\n",
            "\n",
            "--- Evaluating Optimizer: SGD ---\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.9823 - loss: 0.0540\n",
            "\n",
            "\n",
            "--- Optimizer Comparison Summary ---\n",
            "optimizer  test_loss  test_accuracy\n",
            "     adam   0.028894         0.9908\n",
            "  rmsprop   0.035784         0.9892\n",
            "      sgd   0.054013         0.9823\n"
          ]
        }
      ]
    }
  ]
}